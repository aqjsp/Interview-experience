# 理想汽车C++二面面经

> 来源：https://www.nowcoder.com/discuss/397761865479106560

## Linux

### 1、实习项目介绍

### 2、stl

### 3、linux rcu？

Linux内核中的RCU（Read-Copy Update）是一种用于实现无锁并发读取的机制。它适用于读操作频繁、写操作相对较少的场景，比如大多数情况下读取远远多于写入的数据库或者缓存等。

RCU的核心思想是通过“读者-复制-更新”的方式来实现读取数据的并发访问。

1. 读者（Readers）：读者是指那些并发读取数据的线程或者进程。在RCU中，读者可以同时访问数据，而不需要加锁。
2. 复制（Copy）：RCU通过在更新数据时不直接修改原始数据，而是创建一个新的副本来实现更新。这样做的好处是，读者可以继续访问原始数据，而不会受到更新操作的影响。
3. 更新（Update）：当需要对数据进行更新时，RCU会创建一个新的数据副本，并在适当的时机将新旧数据副本进行替换。在替换过程中，RCU会确保已经获取了旧数据副本的读者可以继续访问旧数据，直到它们完成对旧数据的访问为止。
4. 同步（Synchronization）：在RCU中，同步的机制通常是通过一些特殊的原子操作来实现的，比如使用特殊的内存屏障（Memory Barrier）指令来确保数据的一致性。
5. 回收（Reclamation）：在更新操作完成后，RCU会负责回收旧数据副本所占用的内存空间。这个过程通常会延迟执行，以确保已经获取了旧数据副本的读者可以继续访问旧数据。

### 4、linux ping的整个过程，从系统调用到网卡到传输过程？

1. 系统调用：当用户在命令行输入ping命令并按下回车键时，Shell会解析该命令并调用相应的系统调用（比如fork和execve）创建并执行ping程序。
2. ping程序：ping程序首先会解析用户输入的参数，确定目标主机的IP地址或域名，并创建一个ICMP（Internet Control Message Protocol）数据包，用于向目标主机发送ping请求。
3. ICMP数据包：ICMP数据包是ping命令的核心，它包含了ping请求的相关信息，比如目标主机的IP地址、ping命令的标识符和序列号等。
4. 传输层：ICMP数据包被传递到传输层，通常是通过socket API发送到网络层。在发送ICMP数据包之前，ping程序会创建一个原始套接字（raw socket），以便可以直接访问网络层协议（IP协议）。
5. 网络层：ICMP数据包被传递到网络层，网络层负责将数据包封装成IP数据报并通过路由选择算法选择合适的路径发送到目标主机。
6. 数据链路层：IP数据报被传递到数据链路层，数据链路层根据目标主机的MAC地址将数据包发送到本地网络的网卡。
7. 网卡：网卡接收到数据包后，会进行CRC校验等操作，然后将数据包发送到物理网络上。
8. 物理网络：数据包在物理网络上传输，经过各种设备（如交换机、路由器）转发，最终到达目标主机。
9. 目标主机：目标主机接收到ICMP数据包后，会根据数据包中的信息生成响应数据包，并通过类似的网络协议栈将响应数据包发送回源主机。
10. 返回数据包：返回的ICMP数据包经过类似的网络协议栈传输到源主机，ping程序接收到响应数据包后，计算往返时间（RTT）等统计信息，并在命令行上显示结果。

### 5、linux网卡消息队列？

在 Linux 中，网卡消息队列通常指的是网络设备驱动程序（Network Device Driver）中的接收队列（Receive Queue）和发送队列（Transmit Queue）。这些队列用于在网络设备和系统内核之间传输数据包。

1. 接收队列：

   - 接收队列是用于存储从网络中接收到的数据包的地方。当网卡接收到一个数据包时，它会将数据包放入接收队列中，并触发中断通知系统内核有数据包需要处理。
   - 系统内核会定期检查接收队列，当检测到有数据包到达时，会将数据包从接收队列中取出并交给网络协议栈进行处理，比如解析IP头部、查找路由、交付给上层协议等。

2. 发送队列：

   - 发送队列是用于存储需要发送到网络中的数据包的地方。当应用程序通过系统调用将数据包发送到网络时，数据包会被放入发送队列中。
   - 网络设备驱动程序会定期检查发送队列，将队列中的数据包取出并通过网卡发送到网络中。

3. 中断处理：

   网卡接收到数据包时会触发一个中断，通知系统内核有数据包需要处理。中断处理程序会将数据包放入接收队列，并唤醒可能在等待数据包的进程。

4. 性能优化：

   - 为了提高网络性能，可以对接收队列和发送队列进行优化。比如使用多队列（Multiqueue）技术，将接收队列和发送队列分成多个队列，以提高并发处理能力。
   - 另外，还可以通过调整队列的长度、优化中断处理程序等方式来优化网络设备的性能。

### 6、linux伙伴系统，优缺点？


Linux伙伴系统（Buddy System）是Linux内核中用于管理物理内存的一种算法。它将系统的物理内存划分为大小相等的块，并使用一种特殊的算法来管理这些块，以便有效地分配和释放内存。

1. 工作原理：
   - 在Linux伙伴系统中，物理内存被划分为大小相等的块，每个块的大小通常是2的幂次方（如2KB、4KB、8KB等）。
   - 初始时，整个物理内存被看作是一个大的块，大小为系统可用内存的总大小，然后根据需要逐渐划分成更小的块，直到每个块的大小符合要求。
   - 当有内存请求时，伙伴系统会根据请求的大小找到合适的大小的块，并将其分配给请求的进程。如果没有完全匹配的块，系统会找到比请求稍大一些的块，然后将其分割成两个较小的块，其中一个块分配给请求的进程，另一个块保留在伙伴系统中以备将来使用。
   - 当进程释放内存时，伙伴系统会尝试将被释放的块与其他相邻的空闲块合并，以尽量减少碎片化。
2. 优点：
   - 简单高效：伙伴系统算法相对简单，实现起来高效。
   - 最小碎片化：伙伴系统可以最大程度地减少内存碎片化，提高内存利用率。
   - 分配速度快：由于内存块的大小是固定的，因此可以快速找到合适大小的空闲块进行分配。
3. 缺点：
   - 外部碎片：由于伙伴系统要求内存块的大小是2的幂次方，因此可能会产生外部碎片，导致一些较大的内存请求无法得到满足。
   - 内存浪费：伙伴系统中的块大小是固定的，可能会导致一些小的内存请求浪费较多的内存。

### 7、linux进程调度算法？

1. **CFS 调度算法**：

   - CFS 是 Linux 内核中默认的进程调度算法，它的设计目标是实现公平地分配 CPU 时间给各个进程，保证每个进程都能够获得公平的 CPU 时间片。
   - CFS 将系统中的所有可运行进程组织成一棵红黑树（红黑树是一种自平衡的二叉查找树），树中的每个节点代表一个进程或者一个进程组。
   - 红黑树的每个节点包含了进程的运行时间（即进程在 CPU 上运行的时间）和虚拟运行时间（即进程应该获得的 CPU 时间），CFS 会根据这些信息来选择下一个要执行的进程。
   - CFS 通过不断地选择具有最小虚拟运行时间的进程来实现公平调度，这样可以保证每个进程在单位时间内获得的 CPU 时间与其应该获得的 CPU 时间成比例。

   调度策略：

   - CFS 的调度策略是按照进程的虚拟运行时间来进行调度的，即每次选择具有最小虚拟运行时间的进程来执行。
   - 当一个进程被选中执行时，它的虚拟运行时间会被增加，表示它已经消耗了一定的 CPU 时间，同时其优先级会降低，以便下次被其他进程取代。
   - 如果有多个进程具有相同的最小虚拟运行时间，CFS 会选择其中一个进行执行，并将其从红黑树中取出放入运行队列中执行。

   特点：

   - CFS 算法是一种抢占式调度算法，即如果有更高优先级的进程到达，CFS 会立即停止当前进程的执行并选择更高优先级的进程执行。
   - CFS 算法实现了近似公平性，即使在高负载情况下也能够尽量保证每个进程获得公平的 CPU 时间。

2. **实时进程调度**：

   - Linux 提供了多种实时进程调度算法，如 SCHED_FIFO 和 SCHED_RR 等。

   - SCHED_FIFO 使用先进先出的策略，即优先级最高的进程先执行，直到该进程主动释放 CPU 或者被更高优先级的进程抢占。

   - SCHED_RR 是基于 SCHED_FIFO 的轮转调度算法，在 SCHED_FIFO 的基础上增加了时间片的概念，使得低优先级的实时进程也能获得一定的 CPU 时间。

3. **O(1) 调度器**：

   - O(1) 调度器是 Linux 内核早期使用的一种进程调度算法，它的主要特点是调度时间复杂度为 O(1)。
   - O(1) 调度器通过维护多个进程队列和优先级数组，以常数时间内选择下一个要执行的进程。

### 8、线程交互过程？

1. **线程的创建**：
   - 线程的创建是指在应用程序中新建一个线程的过程。在 Linux 下，可以使用 `pthread_create` 函数创建线程。
   - 创建线程时需要指定线程的入口函数和传递给入口函数的参数。
2. **线程的同步**：
   - 线程的同步是指多个线程之间通过某种方式协调彼此的行为，以避免出现竞态条件等并发问题。
   - 常见的线程同步机制包括互斥锁、条件变量、信号量等，这些机制可以通过对临界区的保护、线程的等待和唤醒等方式来实现线程之间的同步。
3. **线程的通信**：
   - 线程的通信是指多个线程之间通过某种方式交换信息或者共享资源的过程。
   - 在 Linux 下，线程之间的通信可以通过共享内存、消息队列、信号量等方式来实现。
4. **线程的销毁**：
   - 线程的销毁是指线程执行完任务后或者出现错误时结束线程的过程。
   - 在 Linux 下，可以使用 `pthread_join` 函数等待线程结束，并回收线程的资源。

### 9、Linux io mmu？

1. **IO（Input/Output）**：
   - IO 是指计算机系统与外部设备之间的数据交换过程，例如磁盘、网络、键盘、显示器等。
   - 在 Linux 中，IO 主要由设备驱动程序来管理，驱动程序负责向硬件发送命令、接收数据，并将数据传输到内存中或者从内存中读取数据。
   - Linux 通过文件系统的方式来访问 IO 设备，即将 IO 设备映射为文件，通过文件操作来进行 IO 操作。
2. **MMU（Memory Management Unit）**：
   - MMU 是计算机系统中的一个硬件组件，用于管理内存的访问和地址映射。
   - 在 Linux 中，MMU 负责将虚拟地址转换为物理地址，实现了虚拟内存的概念。
   - MMU 通过页表等数据结构来实现虚拟地址到物理地址的映射，同时还负责内存的访问权限管理和内存保护。
3. **IO 和 MMU 的关系**：
   - 在 Linux 中，IO 和 MMU 是系统中两个独立但密切相关的组件。
   - IO 设备通过 MMU 提供的地址映射机制访问内存，将数据传输到内存中或者从内存中读取数据。
   - MMU 负责管理 IO 设备访问内存的权限和地址映射，确保 IO 设备只能访问被允许的内存区域。

### 10、对于实时性的理解？

实时性是指系统在规定的时间内完成对外部事件的响应或者处理任务的能力。实时性可以分为硬实时和软实时两种类型：

1. **硬实时**：
   - 硬实时要求系统能够在严格的时间限制内完成任务的处理，即使是微秒级的延迟也是不可接受的。
   - 硬实时系统通常用于对时间敏感性要求极高的场景，如航空航天、医疗设备、工业控制等领域。
2. **软实时**：
   - 软实时系统对任务的时间限制要求相对较宽松，允许在一定范围内出现一定程度的延迟。
   - 软实时系统通常用于对时间敏感性要求较低的场景，如多媒体应用、通信系统等领域。

在实时系统中，要保证实时性，需要考虑以下几个方面：

- **任务调度**：合理的任务调度算法能够保证高优先级任务优先得到处理。
- **中断处理**：及时响应硬件中断，尽快地处理硬件事件。
- **资源管理**：合理分配系统资源，避免资源争用和竞争。

### 11、实时系统调度相关？

1. **任务优先级**：
   - 实时系统中，任务通常具有不同的优先级，高优先级任务需要优先得到处理。
   - 任务的优先级决定了它在系统中的执行顺序，高优先级任务可以抢占低优先级任务的执行。
2. **调度延迟**：
   - 实时系统对任务的调度延迟要求非常严格，即任务被调度执行的时间应该尽可能地接近任务被触发的时间。
   - 系统的调度延迟要尽可能地小，以确保对实时事件的及时响应。
3. **调度算法**：
   - 实时系统通常采用静态优先级调度算法，如静态优先级调度（Static Priority Scheduling）和 Earliest Deadline First（EDF）调度算法。
   - 静态优先级调度算法是指任务的优先级在任务创建时确定，并在任务生命周期内保持不变。
   - EDF 调度算法是指根据任务的最后期限来进行调度，最早截止期限的任务先执行。
4. **中断处理**：
   - 实时系统对中断处理的时间也有严格要求，需要尽快地响应中断事件并进行处理。
   - 中断处理程序的执行时间应该尽可能地短，以减少对实时任务的影响。
5. **资源分配**：
   - 实时系统需要合理地管理系统资源，确保高优先级任务能够及时地获取到所需的资源。
   - 资源的分配应该考虑到任务的优先级和实时性要求，避免资源争用和竞争导致的延迟增加。

### 12、cpu多级缓存如何保证一致性？

1. **缓存一致性协议**：
   - CPU 多级缓存通常会采用缓存一致性协议（Cache Coherence Protocol），如 MESI 协议（Modified, Exclusive, Shared, Invalid）等。
   - 这些协议定义了缓存之间如何协作，以确保缓存中的数据与主存中的数据保持一致。
2. **缓存行填充**：
   - 当 CPU 访问一个内存地址时，如果该地址所在的缓存行不存在于 CPU 缓存中，则需要从主存中加载该缓存行。
   - 在加载缓存行时，CPU 会同时加载相邻的多个缓存行，以提高缓存的命中率。
   - 这样做可以减少由于多次访存引起的性能开销，并且能够保证缓存中的数据与主存中的数据保持一致。
3. **缓存写策略**：
   - CPU 多级缓存通常有多种缓存写策略，如写回（Write Back）和写直达（Write Through）。
   - 写回策略会先将数据写入缓存，然后在一定条件下再将数据写回主存，这样可以减少对主存的访问次数，提高性能。
   - 写直达策略会直接将数据写入主存，这样可以保证数据的一致性，但可能会增加对主存的访问延迟。
4. **缓存失效处理**：
   - 当缓存中的数据发生失效时，CPU 需要根据缓存一致性协议来处理失效的数据。
   - 处理失效数据时，CPU 可能需要向其他 CPU 发送失效请求或者从其他 CPU 接收失效通知，以确保所有 CPU 缓存中的数据都是一致的。

### 13、两面都无算法题

